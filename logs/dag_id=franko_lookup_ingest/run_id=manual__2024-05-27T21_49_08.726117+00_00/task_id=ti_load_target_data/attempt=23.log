[2024-05-28T02:54:14.722+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: franko_lookup_ingest.ti_load_target_data manual__2024-05-27T21:49:08.726117+00:00 [queued]>
[2024-05-28T02:54:14.731+0000] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: franko_lookup_ingest.ti_load_target_data manual__2024-05-27T21:49:08.726117+00:00 [queued]>
[2024-05-28T02:54:14.731+0000] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2024-05-28T02:54:14.731+0000] {taskinstance.py:1284} INFO - Starting attempt 23 of 23
[2024-05-28T02:54:14.731+0000] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2024-05-28T02:54:14.743+0000] {taskinstance.py:1304} INFO - Executing <Task(DockerOperator): ti_load_target_data> on 2024-05-27 21:49:08.726117+00:00
[2024-05-28T02:54:14.748+0000] {standard_task_runner.py:55} INFO - Started process 2150 to run task
[2024-05-28T02:54:14.750+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'franko_lookup_ingest', 'ti_load_target_data', 'manual__2024-05-27T21:49:08.726117+00:00', '--job-id', '237', '--raw', '--subdir', 'DAGS_FOLDER/challenge_dag.py', '--cfg-path', '/tmp/tmp0v7n78ol']
[2024-05-28T02:54:14.750+0000] {standard_task_runner.py:83} INFO - Job 237: Subtask ti_load_target_data
[2024-05-28T02:54:14.794+0000] {task_command.py:389} INFO - Running <TaskInstance: franko_lookup_ingest.ti_load_target_data manual__2024-05-27T21:49:08.726117+00:00 [running]> on host a64b6410e10e
[2024-05-28T02:54:14.848+0000] {taskinstance.py:1513} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=franko_lookup_ingest
AIRFLOW_CTX_TASK_ID=ti_load_target_data
AIRFLOW_CTX_EXECUTION_DATE=2024-05-27T21:49:08.726117+00:00
AIRFLOW_CTX_TRY_NUMBER=23
AIRFLOW_CTX_DAG_RUN_ID=manual__2024-05-27T21:49:08.726117+00:00
[2024-05-28T02:54:14.862+0000] {docker.py:284} INFO - Starting docker container from image my_dbt
[2024-05-28T02:54:16.491+0000] {docker.py:354} INFO - [0m02:54:16  Running with dbt=1.5.11
[2024-05-28T02:54:16.592+0000] {docker.py:354} INFO - [0m02:54:16  Registered adapter: postgres=1.5.11
[2024-05-28T02:54:16.652+0000] {docker.py:354} INFO - [0m02:54:16  Found 6 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 1 seed file, 1 source, 0 exposures, 0 metrics, 0 groups
[2024-05-28T02:54:16.653+0000] {docker.py:354} INFO - [0m02:54:16
[2024-05-28T02:54:16.719+0000] {docker.py:354} INFO - [0m02:54:16  Concurrency: 4 threads (target='dev')
[2024-05-28T02:54:16.719+0000] {docker.py:354} INFO - [0m02:54:16
[2024-05-28T02:54:16.722+0000] {docker.py:354} INFO - [0m02:54:16  1 of 2 START sql table model dev.golden_data ................................... [RUN]
[2024-05-28T02:54:45.109+0000] {local_task_job.py:224} WARNING - State of this instance has been externally set to restarting. Terminating instance.
[2024-05-28T02:54:45.112+0000] {process_utils.py:133} INFO - Sending Signals.SIGTERM to group 2150. PIDs of all processes in the group: [2150]
[2024-05-28T02:54:45.112+0000] {process_utils.py:84} INFO - Sending the signal Signals.SIGTERM to group 2150
[2024-05-28T02:54:45.113+0000] {taskinstance.py:1483} ERROR - Received SIGTERM. Terminating subprocesses.
[2024-05-28T02:54:45.113+0000] {docker.py:456} INFO - Stopping docker container
[2024-05-28T02:54:55.294+0000] {taskinstance.py:1772} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 430, in execute
    return self._run_image()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 303, in _run_image
    return self._run_image_with_mounts(self.mounts, add_tmp_variable=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 351, in _run_image_with_mounts
    for log_chunk in logstream:
  File "/home/airflow/.local/lib/python3.7/site-packages/docker/types/daemon.py", line 32, in __next__
    return next(self._stream)
  File "/home/airflow/.local/lib/python3.7/site-packages/docker/api/client.py", line 418, in <genexpr>
    gen = (data for (_, data) in gen)
  File "/home/airflow/.local/lib/python3.7/site-packages/docker/utils/socket.py", line 106, in frames_iter_no_tty
    (stream, n) = next_frame_header(socket)
  File "/home/airflow/.local/lib/python3.7/site-packages/docker/utils/socket.py", line 78, in next_frame_header
    data = read_exactly(socket, 8)
  File "/home/airflow/.local/lib/python3.7/site-packages/docker/utils/socket.py", line 63, in read_exactly
    next_data = read(socket, n - len(data))
  File "/home/airflow/.local/lib/python3.7/site-packages/docker/utils/socket.py", line 34, in read
    select.select([socket], [], [])
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1485, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2024-05-28T02:54:55.311+0000] {taskinstance.py:1327} INFO - Marking task as UP_FOR_RETRY. dag_id=franko_lookup_ingest, task_id=ti_load_target_data, execution_date=20240527T214908, start_date=20240528T025414, end_date=20240528T025455
[2024-05-28T02:54:55.342+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 237 for task ti_load_target_data (Task received SIGTERM signal; 2150)
[2024-05-28T02:54:55.352+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=2150, status='terminated', exitcode=1, started='02:54:13') (2150) terminated with exit code 1
